KR-WordRank, 토크나이저를 이용하지 않는 한국어 키워드 추출기

PageRank 나 HITS 같은 graph ranking 알고리즘은 natural language processing 에서 이용되기도 합니다.
WordRank는 일본어와 중국어의 unsupervised word segmentation 을 위하여 제안된 방법입니다.
하지만 이 알고리즘을 한국어에 그대로 적용하기는 어렵습니다. 한국어와 일본어, 중국어는 언어적 특성이 다릅니다.
KR-WordRank는 한국어의 특징을 반영하여 비지도학습 기반으로 한국어의 단어를 추출합니다.
그리고 단어 점수는 키워드 점수로 이용될 수도 있습니다.
즉, KR-WordRank는 토크나이저를 이용하지 않으면서도 단어/키워드 추출을 비지도학습 기반으로 수행합니다.

Brief review of HITS
PageRank와 HITS는 비슷한 시기에, 비슷한 아이디어로, 비슷한 문제를 해결하였습니다.
HITS의 아이디어는 "중요한 웹페이지는 좋은 웹페이지로부터 링크를 많이 받은 페이지이고, 각 페이지의 authority는 중요한 웹페이지로부터의
링크가 많을수록 높다" 입니다. 이 아이디어를 그대로 공식으로 표현하였습니다.

마디 p의 hub score는 backlinks 의 출발 마디인 q의 authority score 의 합입니다.
마디 p의 authority score는 backlinks 의 출발 마디인 q의 hub score 의 합입니다.
이 식을 hub and authority score 가 수렴할 때 까지 반복합니다.
초기화는 모든 마디에 같은 값을 hub and authority score 로 설정합니다.

이는 PageRank의 아이디어와도 비슷합니다.
PageRank 는 중요한 web pages 로부터 많은 basklinks 를 받을수록 그 페이지도 중요한 web pages라 가정합니다.
PageRank와 HITS 모두 각 마디의 중요성을 다른 마디와의 관계식으로 표현합니다.

두 알고리즘의 차이점 중 하나는, PageRank 는 아래처럼 각 페이지의 랭크를 링크의 갯수만큼 나눠서 연결된 페이지로 보내주는 반면, 
HITS는 점수가 복제되어 링크된 페이지로 전달됩니다. 그리고 점수의 총합을 유지하기 위하여 normalize 를 합니다.

WordRank
WordRank 는 띄어쓰기가 없는 중국어와 일본어에서 graph ranking 알고리즘을 이용하여 단어를 추출하기 위해 제안된 방법입니다.
Ranks 는 substring의 단어 가능 점수이며, 이를 이용하여 unsupervised word segmentation 을 수행하였습니다.

WordRank는 substring graph 를 만든 뒤, graph ranking 알고리즘을 학습합니다.
Substring graph 는 아래 그림의 (a), (b) 처럼 구성됩니다.

먼저 문장에서 띄어쓰기가 포함되지 않은 모든 substring의 빈도수를 계산합니다.
이 때 빈도수가 같으면서 짧은 substring 이 긴 substring 에 포함된다면 이를 제거합니다.
아래 그림에서 'seet' 의 빈도수가 2이고, 'seeth' 의 빈도수가 2이기 때문에 'seet'는 graph node 후봉서 제외됩니다.

두번째 단계는 모든 substring nodes에 대하여 links 를 구성합니다. 
'that' 옆에 'see'와 'dog'이 있었으므로 두 마디를 연결합니다. 
왼쪽에 위치한 substring 과 오른쪽에 위치한 substring 의 edge 는 서로 다른 종류로 표시합니다.
이 때, 'do' 역시 'that' 의 오른쪽에 등장하였으므로 링크를 추가합니다.

이렇게 구성된 substring graph 에 HITS 알고리즘을 적용하여 각 substring의 ranking 을 계산합니다.

WordRank 의 가설은 HITS 와 비슷합니다. 단어의 좌/우에는 단어가 등장하고, 단어가 아닌 substring 좌/우에는 단어가 아닌 substring 이 등장합니다.
단어는 다른 많은 단어들과 연결되기 때문에 질 좋은 links 가 많이 연결되며, 단어가 아닌 substring은 소수의 backlinks 를 받습니다.
그 마저도 단어가 아닌 substring 으로부터 출발한 links 입니다.
Ranking update 를 하면, 단어들을 rank가 높아집니다.

한 substring 의 왼쪽이 단어의 경계일 점수는 왼쪽에 위치한 substring 의 오른쪽 단어 경계 점수의 합으로,
한 substring 의 오른쪽이 단어의 경계일 점수는 오른쪽에 위치한 substring 의 왼쪽 단어 경계 점수의 합으로 표현됩니다.
왼쪽이 단어 경계라면 같은 경계를 마주한 다른 단어의 오른쪽 단어 경계 점수가 높아야 하기 때문입니다.
이는 HITS처럼 아래의 식으로 표현할 수 있습니다. 
lbv(s) 는 substring s의 left boundary value 이며, L(s)는 s의 왼쪽에 위치한 substrings 집합입니다.

WordRank 를 한국어 데이터에 적용하였습니다. 이를 위하여 원빈 주연의 한국 영화 '아저씨'의 사용자 영화평 데이터를 이용하였습니다.

WordRank 알고리즘을 한국어에 그대로 적용하는데는 무리가 있습니다.
한국어 데이터에 WordRank를 적용하면 한 글자들이 높은 ranking을 지닙니다.
한국어의 한 글자는 그 자체로 단어이기도 하며, 관형사나 조사로 이용되는 글자들이 많아 단어로 등장합니다.

한 글자 단어를 제거하여 살펴보면 '-지만', '-네요' 와 같은 suffix 들이 높은 rank 를 받습니다.
어근이나 명사들의 종류가 조사나 어미보다 다양하여 조사나 어미의 ranking 이 상대적으로 높습니다.

또한 '영화', '원빈' 이 높은 ranking 을 받음에도 '원빈이', '원빈의', '영화가' 등의 어절도 높은 ranking 을 받습니다.
중복된 정보가 출력됩니다.

KR-WordRank
WordRank 를 한국어 데이터에 그대로 적용하는 것은 무리가 있습니다.
WordRank는 중국어와 일본어에 적용하기 위하여 개발된 알고리즘이기 때문입니다. 언어적 특징이 다르니, 그 특징을 잘 이용해야 합니다.

한국어는 띄어쓰기 정보를 이용해야 합니다. 띄어쓰기 정보를 이용하지 않으면 두 어절의 양끝에 걸친 substring 역시 단어 후보에 포함됩니다.
띄어쓰기로 구분되는 '번봄'은 substring graph 에 추가할 필요가 없습니다.
물론 띄어쓰기 오류가 일부 존재하여 '번봄'이 마디에 포함될 수 있습니다.
하지만 그 빈도는 매우 작기 때문에 ranking 이 매우 낮게 계산될 겁니다.

substring('이번봄에는') = [이번, 번봄, 봄에, 에는, 이번봄, 번봄에, ...]
substring('이번 봄에는') = [이번, 봄에, 에는, 봄에는]

한국어 어절 구조의 특징인 L+[R] 을 이용해야 합니다. 어절의 왼쪽에 위치한 글자들이 의미를 지니는 단어들이며,
오른쪽에 위치한 글자들은 문법기능을 하는 조사와 어미입니다.
우리가 단어 사전으로 만들고 싶은 단어들은 L parts 입니다.

더하여 WordRank 알고리즘은 keyword extraction 능력이 있습니다.
Substring graph 에서 ranking 이 높은 마디는 단어일 뿐 아니라, 그 데이터셋에서 자주 등장하는 단어입니다.
데이터를 요약하는 keywords 로 이용될 수 있습니다.

KR-WordRank는 이러한 성질을 바탕으로 unsupervised Korean keyword extraction 을 수행합니다.

KR-WordRank 역시 WordRank 와 같은 가정을 합니다.
단어의 좌/우에 등장하는 substring 은 단어일 것이며, 단어가 아닌 substring 은 단어가 아닌 substring 와 연결됩니다.

KR-WordRank 의 학습 과정은 WordRank 과정과 조금 다릅니다.
첫 단계는 substring frequency counting 입니다.
빈 도수를 계산할 substring 은 어절의 왼쪽에 위치하거나 (어절 전체는 어절 왼쪽에 위치하는 것으로 간주합니다),
어절의 오른쪽에 위치한 substring 입니다. 그리고 각각의 position 을 L과 R로 구분합니다.

3 단계에서 가능한 모든 substring 의 빈도수를 계산하고, 같은 position 이면서 빈도수가 같은 substrings 은 제거합니다.

4 단계에서는 substrings 간의 링크를 만듭니다. 어절 내 L과 R의 어절 간 링크를 구성합니다.

5 단계에서 graph ranking 을 학습하고, 6 단계에서 후처리를 진행합니다.
5 단계의 결과 영화 '아저씨'의 리뷰에서는 '원빈/L'과, '원빈은/L' 모두 높은 ranking 을 가집니다.
상위 rank를 지닌 R은 조사나 어미일 가능성이 높습니다.
top k (약 300개) 의 상위 rank R 을 suffix set 으로 선택합니다.
그 뒤, rank 기준으로 L을 필터링합니다.

'원빈/L','원빈은/L','원빈이/L','아저씨/L' 순서로 ranking을 지니고 '은/R','이/R' suffix set 에 포함되어 있다면,
ranking 이 높은 순서대로 L을 확인합니다. 필터링의 첫 시작은 ranking 이 가장 높은 단어를 filtered set 에 추가하는 것입니다.
'원빈/L'이 filtered set 에 추가되었습니다. 그 다음부터는 L 이 이미 filtered set 에 포함된 L과 suffix set 으로 조합되는지 확인합니다.
'원빈은/L = 원빈/L + 은/R' 이므로 filtered set 에 추가하지 않습니다.
'원빈이/L = 원빈/L + 이/R' 이므로 filtered set 에 추가하지 않습니다.
하지만 '아저씨/L' 는 filtered set + suffix set 으로 조합할 수 없기 때문에 filtered set 에 추가합니다.

...

SoftWards

Input data 는 list of str 형식입니다. normalize 함수는 불필요한 특수기호를 제거하는 전처리 함수입니다.
englist=True, number=True 를 입력하면 한글, 영어, 숫자를 제외한 다른 글자를 제거합니다.
Default 는 english=False, number=False 입니다.

